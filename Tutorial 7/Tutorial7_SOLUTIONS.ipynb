{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtmEXONlGRN"
      },
      "source": [
        "\n",
        "#Graph methods for imaging, Vision and computing (B31RX) 2025\n",
        "\n",
        "##Tutorial 7: Bayesian smoothing with Gaussian densities: the Rauch-Tung-Striebel (RTS) smoother\n",
        "\n",
        "In this tutorial, we will apply the sum-product algorithm to extend the Kalman filter from the THA and implement a Bayesian smoother for estimating a multivariate Gaussian state. Following the reasoning of tutorial 6, we will first derive the smoothing equations using the Bayes' rule (and variable elimination) and then investigate how the sum-product rules can be used to directly compute the marginal distributions of interest.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXwFjOJnb0h"
      },
      "source": [
        "### Background\n",
        "\n",
        "#### Bayesian model:\n",
        "\n",
        "We consider a multivariate state denoted $ \\mathbf{p}_t \\in \\mathbb{R}^4 $. This state can vary over time with $ t \\in \\{1, \\dots, T\\} $.\n",
        "\n",
        "The variations of $ \\mathbf{p} $ over time are modelled a priori by a homogeneous order-1 Markov chain with transition kernel:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{p}_t \\mid \\mathbf{p}_{t-1}) = \\mathcal{N}(\\mathbf{p}_t ; \\mathbf{Q} \\mathbf{p}_{t-1}, \\mathbf{R}),\n",
        "$$\n",
        "\n",
        "where $ \\mathbf{Q} $ and $ \\mathbf{R} $ have been defined in the THA.\n",
        "\n",
        "The state $ \\mathbf{p} $ is not observed directly. Instead, it is partially observed via the observations $ \\mathbf{y}_t \\in \\mathbb{R}^2 $, such that:\n",
        "\n",
        "$$\n",
        "\\mathbf{y}_t = \\mathbf{B} \\mathbf{p}_t + \\mathbf{w}_t,\n",
        "$$\n",
        "\n",
        "where $ \\mathbf{B} $ is also defined in the THA and $ \\mathbf{w}_t \\sim \\mathcal{N}(\\mathbf{w}_t; \\mathbf{0}, \\sigma_n^2 \\mathbf{I}_2) $.\n",
        "\n",
        "In the THA, we investigated a sequential, online filtering method to compute\n",
        "\n",
        "$$\n",
        "f(\\mathbf{p}_t \\mid \\mathbf{Y}_t),\n",
        "$$\n",
        "\n",
        "with $ \\mathbf{Y}_t = \\{ \\mathbf{y}_1, \\dots, \\mathbf{y}_t \\} $, i.e., the posterior distribution of $ \\mathbf{p}_t $ conditioned on all the observations previously observed (i.e., not the future observations).  \n",
        "Here we will compute the marginal distributions\n",
        "\n",
        "$$\n",
        "f(\\mathbf{p}_t \\mid \\mathbf{Y}_T), \\quad \\forall t\n",
        "$$\n",
        "\n",
        "which can be computed once the whole sequence of observations has been\n",
        "observed. The Bayesian filter associated with the Kalman filter is called the Rauch-Tung-Striebel (RTS) smoother.\n",
        "\n",
        "We will first show that the marginal distributions above can be computed analytically using a brute force approach by first computing the joint posterior distribution\n",
        "\n",
        "$$\n",
        "f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T \\mid \\mathbf{Y}_T),\n",
        "$$\n",
        "\n",
        "and marginalising all but one state."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "Does the joint prior distribution $ f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T) $ belong to a known family of parametric distributions?  \n",
        "If so, explain which family and why."
      ],
      "metadata": {
        "id": "LQCW8ivnoL9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\color{blue}{f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T) = f(\\mathbf{p}_1) \\prod_{t=2}^T f(\\mathbf{p}_t \\mid \\mathbf{p}_{t-1})}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{Introducing the stacked vector:}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "\\mathbf{P} =\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{p}_1 \\\\\n",
        "\\mathbf{p}_2 \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{p}_T\n",
        "\\end{bmatrix},\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{we can show that:}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "f(\\mathbf{P}) \\propto \\exp\\left( -\\frac{1}{2} (\\mathbf{P} - \\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1} (\\mathbf{P} - \\boldsymbol{\\mu}) \\right)\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{Hence, $ f(\\mathbf{P}) $ is a multivariate Gaussian density.}}$"
      ],
      "metadata": {
        "id": "Z3qtLklrqdfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "\n",
        "Using Bayes' rule, show that $ f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T \\mid \\mathbf{Y}_T) $ belongs to a known family of parametric distributions."
      ],
      "metadata": {
        "id": "rolqhIfBoWJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\color{blue}{\\text{Similarly, the likelihood of the full observation vector $ \\mathbf{Y}_T $ given the state trajectory $ \\mathbf{P} $ takes the form:}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "f(\\mathbf{Y}_T \\mid \\mathbf{P}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} (\\mathbf{Y}_T - \\mathbf{E} \\mathbf{P})^\\top (\\mathbf{Y}_T - \\mathbf{E} \\mathbf{P}) \\right)\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{with}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "\\mathbf{E} =\n",
        "\\begin{bmatrix}\n",
        "\\mathbf{B} & \\mathbf{0} & \\cdots & \\mathbf{0} \\\\\n",
        "\\mathbf{0} & \\mathbf{B} & \\cdots & \\mathbf{0} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "\\mathbf{0} & \\mathbf{0} & \\cdots & \\mathbf{B}\n",
        "\\end{bmatrix}\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{This is again a Gaussian in $\\mathbf{P}$.}}$\n",
        "\n",
        "$\\color{blue}{\\text{From Bayes' rule:}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "f(\\mathbf{P} \\mid \\mathbf{Y}_T) \\propto f(\\mathbf{P}) f(\\mathbf{Y}_T \\mid \\mathbf{P})\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{Since both terms on the right-hand side are Gaussian in $ \\mathbf{P} $, their product is also Gaussian.}}$\n",
        "\n",
        "$\\color{blue}{f(\\mathbf{P} \\mid \\mathbf{Y}_T) \\text{ is Gaussian}}$"
      ],
      "metadata": {
        "id": "NyOrt_Ygtg7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "Using the previous results, which family does $ f(\\mathbf{p}_t \\mid \\mathbf{Y}_T) $ belong to?  \n",
        "How can one compute its moments (e.g., mean and covariance)?\n",
        "\n",
        "This computation starting from $ f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T \\mid \\mathbf{Y}_T) $ can be extremely expensive, especially for long sequences due to large matrix inversion required when marginalising variables. However, we can compute the marginals more efficiently using the **sum-product algorithm**."
      ],
      "metadata": {
        "id": "opCYziZboWGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\color{blue}{\\text{Since marginals of multivariate Gaussians are also Gaussian, we have:}}$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "f(\\mathbf{p}_t \\mid \\mathbf{Y}_T) \\text{ is Gaussian}\n",
        "}\n",
        "$$\n",
        "\n",
        "$\\color{blue}{\\text{Marginal moments:}}$\n",
        "\n",
        "$\\color{blue}{\\text{- The mean of $ \\mathbf{p}_t $ can be extracted from the joint mean vector of $ \\mathbf{P} $.}}$\n",
        "$\\color{blue}{\\text{- The covariance of $ \\mathbf{p}_t $ corresponds to the diagonal block $ (4 \\times 4) $ of the full covariance matrix of $ \\mathbf{P} $.}}$"
      ],
      "metadata": {
        "id": "CZyjdEFWv1Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "Draw the factor graph (FG) associated with the Bayesian model:\n",
        "\n",
        "$$\n",
        "f(\\mathbf{p}_1, \\dots, \\mathbf{p}_T, \\mathbf{y}_1, \\dots, \\mathbf{y}_T).\n",
        "$$"
      ],
      "metadata": {
        "id": "os7ulJcvoWDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BISC-Group-HWU/B31XR.git\n",
        "%cd B31XR/Tutorial\\ 7\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename='T7-Q4.png'))"
      ],
      "metadata": {
        "id": "jbgHLpU4JHSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "Is this graph a tree?"
      ],
      "metadata": {
        "id": "8LT5H7mKoV36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\color{blue}{\\text{Yes}}$"
      ],
      "metadata": {
        "id": "d1pmTbkAxHA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "Compute the messages from each leaf variable to their neighbours (factor nodes)."
      ],
      "metadata": {
        "id": "Op1GPi5PoVwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$\n",
        "\\color{blue}{\\mu_{y_t \\to \\Phi_t}(y_t) = 1.} \\quad \\color{blue}{\\text{(see lecture }notes)}\n",
        "$$"
      ],
      "metadata": {
        "id": "asvQ2xfIxKBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "\n",
        "Starting from $ \\mathbf{p}_1 $, compute the messages propagating from $ t = 1 $ to $ t = T $."
      ],
      "metadata": {
        "id": "ADscBNyZoVpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(filename='T7-Q7.png'))"
      ],
      "metadata": {
        "id": "pQLeEW2WJLre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\color{blue}{\n",
        "\\mu_{\\mathbf{p}_1 \\to \\Psi_2} = \\mu_{\\Phi_{1} \\to \\mathbf{p}_1} \\times \\mu_{\\Psi_{1} \\to \\mathbf{p}_1} \\quad \\text{(\"posterior\")}\n",
        "}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "\\mu_{\\Psi_t \\to \\mathbf{p}_t}(\\mathbf{p}_t) = \\int \\Psi_t(\\mathbf{p}_{t-1}, \\mathbf{p}_t) \\, \\mu_{\\mathbf{p}_{t-1} \\to \\Psi_t}(\\mathbf{p}_{t-1}) \\, d\\mathbf{p}_{t-1}\n",
        "\\quad \\text{(\"predictive distribution\")}\n",
        "}\n",
        "$$"
      ],
      "metadata": {
        "id": "xZKYLvdH7iH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "\n",
        "Starting from $ \\mathbf{p}_T $, compute the messages propagating from $ t = T $ to $ t = 1 $."
      ],
      "metadata": {
        "id": "lMlmCTuQoVhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(filename='T7-Q8.png'))"
      ],
      "metadata": {
        "id": "4GqZctEFJNwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\color{blue}{\n",
        "\\mu_{\\Psi_T \\to \\mathbf{p}_{T-1}} = \\int \\Psi_T(\\mathbf{p}_T, \\mathbf{p}_{T-1}) \\, \\mu_{\\mathbf{p}_T \\to \\Psi_T} \\, d\\mathbf{p}_T\n",
        "\\quad \\text{(similar to predictive step)}\n",
        "}\n",
        "$$"
      ],
      "metadata": {
        "id": "kRwDVk87HF2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(filename='T7-Q8-2.png'))"
      ],
      "metadata": {
        "id": "9fLGWtx8HcKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\color{blue}{\\text{Marginal distribution:}}$\n",
        "\n",
        "\n",
        "$$\n",
        "\\color{blue}{\n",
        "f(\\mathbf{p}_t \\mid \\mathbf{Y}_T) \\propto\n",
        "\\mu_{\\Psi_t \\to \\mathbf{p}_t} \\,\n",
        "\\mu_{\\Psi_{t+1} \\to \\mathbf{p}_t} \\,\n",
        "\\mu_{\\Phi_t \\to \\mathbf{p}_t}\n",
        "}\n",
        "$$"
      ],
      "metadata": {
        "id": "LkaR6IxbHcty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "\n",
        "Implement the sum-product algorithm for this Bayesian model and, using the data of the **THA** (with and without missing data), compare the estimation results of the **Bayesian filter (THA)** and the **Bayesian smoother**.\n",
        "\n",
        "What do you remark in the case of missing data?"
      ],
      "metadata": {
        "id": "JllpLv9loVax"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErXhCfItJT3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}