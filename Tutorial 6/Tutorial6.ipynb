{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtmEXONlGRN"
      },
      "source": [
        "\n",
        "#Graph methods for imaging, Vision and computing (B31RX) 2025\n",
        "\n",
        "##Tutorial 6: Bayesian smoothing with a discrete state space\n",
        "\n",
        "In this tutorial, we will extend the filter from tutorial 5 and implement a Bayesian smoother for online estimation of a (scalar) discrete state. We will first derive the smoothing equations using the Bayes' rule (and variable elimination) and then investigate how the sum-product rules can be used to directly compute the marginal distributions of interest.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXwFjOJnb0h"
      },
      "source": [
        "## Background\n",
        "\n",
        "### Bayesian model:\n",
        "\n",
        "We consider a simple state denoted $x_t ∈ \\{0, ..., K-1\\}$, which can take $K$ values at\n",
        "each time instant. This state can vary over time with $t ∈ \\{1, ..., T\\}$\n",
        "\n",
        "\n",
        "The variations of $x$ over time is modelled by a\n",
        "homogeneous order-1 Markov chain such that the  probabilities\n",
        "\n",
        "$$f(x_{t+1} = i | x_t = j) = π_{i,j}$$\n",
        "\n",
        "are assumed to be known. Note that:\n",
        "$Σ_{i=0}^{K-1} π_{i,j} = 1$.\n",
        "\n",
        "This state is the parameter we try to estimate but it is not directly measured. Instead, we observe sequentially a set of observations $y_1, \\ldots, y_T$ distributed to binomial distributions as follows:\n",
        "\n",
        "$$\n",
        "y_t | (x_t = i) \\sim \\text{Binomial}(N, \\beta_i),\n",
        "$$\n",
        "\n",
        "where $N$ is a known integer and $\\beta_0, \\ldots, \\beta_{K-1}$ are a set of known probabilities. More precisely, if $x_t = i$, the observation $y_t$ follows a binomial distribution whose probability of success depends on the value of the state $x_t$. The probability mass function of Binomial distribution with parameters $(N, \\beta)$ is given by\n",
        "\n",
        "$$\n",
        "f(y|N, \\beta) = \\binom{N}{y} \\beta^y (1 - \\beta)^{N-y}.\n",
        "$$\n",
        "\n",
        "For simplicity, the parameter $N$ is shared across all models and does not depend on $x_t$. It should be noted that the data likelihood should be denoted by $f(y_t | (x_t = i, N, \\beta_i))$. However, since $N$ and $\\beta = \\{\\beta_0, \\ldots, \\beta_{K-1}\\}$ are assumed to be known and fixed, they are omitted to simplify the notation.\n",
        "\n",
        "In the previous tutorial, we computed for each time instant, the predictive distribution:\n",
        "\n",
        "$$\n",
        "f(x_t = i \\mid {\\bf{y}}_{t-1}) = \\sum_{j=0}^{K-1} \\pi_{i,j} \\gamma_j, \\quad \\forall i \\in \\{0, K-1\\}\n",
        "$$\n",
        "\n",
        "With\n",
        "\n",
        "$$\n",
        "\\gamma_i = f(x_{t-1} = i \\mid {\\bf{y}}_{t-1})\n",
        "$$\n",
        "\n",
        "and the posterior distribution:\n",
        "\n",
        "$$\n",
        "f(x_t = i \\mid {\\bf{y}}_t), \\forall i.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSZmkQXNvAR6"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Compute the expression of the joint p.m.f. $ f(x_T, x_{T-1} \\mid {\\bf{y}}_{T-1}, y_T) $ using $ f(x_{T-1} \\mid {\\bf{y}}_{T-2}) $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knyN4s9iwn7R"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "By marginalising $ x_T $ from $ f(x_T, x_{T-1} \\mid {\\bf{y}}_{T-1}, y_T) $, show that $ f(x_{T-1} \\mid {\\bf{y}}_T) $ can be expressed as\n",
        "\n",
        "$$\n",
        "f(x_{T-1} \\mid {\\bf{y}}_T) \\propto \\phi_{T-2}(x_{T-1}) G_{T-1}(x_{T-1}) \\Psi_T(x_{T-1}),\n",
        "$$\n",
        "\n",
        "where $ \\phi_{T-2}(\\cdot) $ only depends on data observed at $ t < T-1 $, $ G_{T-1}(\\cdot) $ only depends on $ y_{T-1} $ and $ \\Psi_T(\\cdot) $ only depends on $ y_T $.\n",
        "\n",
        "Provide the expression of $ \\phi_{T-2}(\\cdot) $, $ G_{T-1}(\\cdot) $ and $ \\Psi_T(\\cdot) $.\n",
        "\n",
        "Note the difference between $ f(x_{T-1} \\mid {\\bf{y}}_{T-1}) $ and $ f(x_{T-1} \\mid {\\bf{y}}_T) $. The former is the marginal distribution of $ x_{T-1} $ obtained after observing $ y_{T-1} $ but before observing $ y_T $, while $ f(x_{T-1} \\mid {\\bf{y}}_T) $ is the marginal distribution of $ x_{T-1} $ obtained after observing all the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "In the context of Tutorial 5, what does the product $ \\phi_{T-2}(x_{T-1}) G_{T-1}(x_{T-1}) $ represent?"
      ],
      "metadata": {
        "id": "-wDZYUSFbA6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "Similarly, compute $ f(x_{T-2} \\mid {\\bf{y}}_T) $, the marginal distribution of $ x_{T-2} $ by starting from\n",
        "\n",
        "$$\n",
        "f(x_T, x_{T-1}, x_{T-2} \\mid {\\bf{y}}_{T-2}, y_{T-1}, y_T)\n",
        "$$\n",
        "\n",
        "and show that it can be expressed as\n",
        "\n",
        "$$\n",
        "f(x_{T-2} \\mid y_T) \\propto \\phi_{T-3}(x_{T-2}) G_{T-2}(x_{T-2}) \\Psi_{T-1}(x_{T-2}).\n",
        "$$\n",
        "\n",
        "Specify what the three factors represent in terms of probability mass functions."
      ],
      "metadata": {
        "id": "AQRM44RXcoSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "Derive the expression of the marginal distribution $ f(x_i \\mid y_T) $, $ \\forall i \\in \\{1, \\dots, T\\} $."
      ],
      "metadata": {
        "id": "lqhbKWl1nDwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we have seen how to compute the marginal distributions of $ f(x_i \\mid {\\bf{y}}_T) $ which requires computing $ \\phi_{t-1}(\\cdot) $, $ G_t(\\cdot) $, and $ \\Psi_{t+1}(\\cdot) $, $ \\forall t \\in \\{1, \\dots, T - 1\\} $.\n",
        "\n",
        "These quantities can actually be computed iteratively by passing twice through the nodes of the graph. We will now derive the results using the rules of the **sum-product algorithm**."
      ],
      "metadata": {
        "id": "hCifhXWDoHQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "Draw the factor graph (FG) associated with the Bayesian model\n",
        "\n",
        "$$\n",
        "f(x_1, \\dots, x_T, y_1, \\dots, y_T).\n",
        "$$"
      ],
      "metadata": {
        "id": "_7zSdDR3obDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "\n",
        "Is this graph a tree?  "
      ],
      "metadata": {
        "id": "Nh8PZra7p1MI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "\n",
        "Compute the messages from each leaf variable to their neighbours (factor nodes)  "
      ],
      "metadata": {
        "id": "-aoHvodsqRb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "\n",
        "Starting from $ x_1 $, compute the messages propagating from $ t = 1 $ to $ t = T $."
      ],
      "metadata": {
        "id": "4Mpg-z2OuuTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 10\n",
        "\n",
        "Starting from $ x_T $, compute the messages propagating from $ t = T $ to $ t = 1 $ and verify the marginal distributions correspond to those found in **Question 5**."
      ],
      "metadata": {
        "id": "6OEQDya1vobA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 11\n",
        "\n",
        "Implement the sum-product algorithm for this Bayesian model and, using the data of **Tutorial 5**, compare the estimation results of the **Bayesian filter (Tutorial 5)** and **Bayesian smoother (this Tutorial 6)**.  \n",
        "\n",
        "What do you remark?"
      ],
      "metadata": {
        "id": "wYMQ7Y_BykRi"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}