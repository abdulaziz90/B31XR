{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtmEXONlGRN"
      },
      "source": [
        "# Graph methods for imaging, Vision, and computing (B31RX) 2025\n",
        "\n",
        "## Tutorial 8: Variational Autoencoders (VAEs)\n",
        "\n",
        "In this tutorial, we will explore the application of variational autoencoders (VAEs), a type of generative model capable of learning the underlying structure of data, for denoising images, specifically using the MNIST dataset of handwritten digits.\n",
        "\n",
        "---\n",
        "\n",
        "### Background\n",
        "\n",
        "Image denoising is an essential preprocessing step in many computer vision and image processing applications. The goal is to remove noise from a given image while preserving the original details and structures as much as possible. Traditional denoising techniques, such as Gaussian filtering or total variation regularization, often struggle to balance noise removal and detail preservation.\n",
        "\n",
        "In recent years, deep learning techniques, including autoencoders and their variants, have shown great potential in denoising tasks. Variational Autoencoders (VAEs) are one such deep learning model, primarily known for their generative capabilities.\n",
        "\n",
        "- VAEs consist of an encoder network that maps input data to a latent space and a decoder network that reconstructs the input data from the latent space.\n",
        "- By optimizing both the reconstruction loss and a regularization term that encourages the latent space to follow a specific distribution, VAEs can learn smooth and structured latent spaces, which can be advantageous for denoising tasks.\n",
        "\n",
        "In this tutorial, we will adapt VAEs for image denoising using the MNIST dataset of handwritten digits. We will explore various aspects of VAEs in the context of denoising, such as:\n",
        "- The effects of noise levels, latent space dimensions, network architecture, and loss functions.\n",
        "\n",
        "By studying these factors, we aim to provide insights into the effective application of VAEs for denoising tasks and their potential improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "Execute the provided code for the VAE with a dense-layer architecture. In the context of the given implementation, explain how Variational Autoencoders (VAEs) differ from traditional autoencoders."
      ],
      "metadata": {
        "id": "o-J61xk_FnoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Some parts of this code (such as the VAE architecture and Sampling layer) are adapted from the official\n",
        "# Keras VAE tutorial: https://keras.io/examples/generative/vae/\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D  # ensures 3D plotting support\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# --------------------------------------\n",
        "# Define the Sampling Layer\n",
        "# --------------------------------------\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = ops.shape(z_mean)[0]\n",
        "        dim = ops.shape(z_mean)[1]\n",
        "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
        "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# --------------------------------------\n",
        "# Define the VAE Model with a Custom Train Step\n",
        "# --------------------------------------\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        self.current_epoch = 0  # initialize current epoch\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the tuple: noisy input and clean target\n",
        "        noisy, clean = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(noisy)\n",
        "            reconstruction = self.decoder(z)\n",
        "            # Compute the reconstruction loss against the clean image\n",
        "            reconstruction_loss = ops.mean(\n",
        "                ops.sum(\n",
        "                    keras.losses.binary_crossentropy(clean, reconstruction),\n",
        "                    axis=(1, 2),\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
        "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
        "            # Pseudo-code for annealing beta:\n",
        "            # current_beta = min(1.0, beta + (self.current_epoch / num_epochs))\n",
        "            total_loss = reconstruction_loss + beta * kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "class EpochTracker(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.model.current_epoch = epoch"
      ],
      "metadata": {
        "id": "hnPPyC8z7iqs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 3\n",
        "num_epochs = 50\n",
        "beta = 1\n",
        "noise_stddev = 0.0\n",
        "\n",
        "# --------------------------------------\n",
        "# Build the Dense Encoder\n",
        "# --------------------------------------\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1), name=\"encoder_input\")\n",
        "x = layers.Flatten()(encoder_inputs)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "# --------------------------------------\n",
        "# Build the Dense Decoder\n",
        "# --------------------------------------\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
        "x = layers.Dense(256, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "decoder_outputs = layers.Reshape((28, 28, 1))(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "# --------------------------------------\n",
        "# Load and Preprocess MNIST Data\n",
        "# --------------------------------------\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# Normalize and add channel dimension\n",
        "x_train = np.expand_dims(x_train[:10000], -1).astype(\"float32\") / 255.0\n",
        "x_test  = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "y_train = y_train[:10000]\n",
        "\n",
        "def add_gaussian_noise(x, stddev=0.0):\n",
        "    noise = np.random.normal(loc=0.0, scale=stddev, size=x.shape)\n",
        "    x_noisy = x + noise\n",
        "    # Clip values to keep them in [0, 1]\n",
        "    return np.clip(x_noisy, 0., 1.)\n",
        "\n",
        "# Add noise with a chosen standard deviation\n",
        "x_train_noisy = add_gaussian_noise(x_train, stddev=noise_stddev)\n",
        "x_test_noisy  = add_gaussian_noise(x_test, stddev=noise_stddev)\n",
        "\n",
        "# --------------------------------------\n",
        "# Create and Train the VAE\n",
        "# --------------------------------------\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(x_train_noisy, x_train, epochs=num_epochs, batch_size=100, callbacks=[EpochTracker()])"
      ],
      "metadata": {
        "id": "18rQYgj73UgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2: Using the VAE for dimensionality reduction\n",
        "\n",
        "Utilize the VAE to perform dimensionality reduction. Compare the latent space representations produced by the VAE for latent dimensions of 2 and 3 with those obtained using principal component analysis (PCA) applied to the raw data. Which method provides a more accurate and meaningful representation of the data?\n",
        "\n",
        "Study and discuss the impact of changing the beta parameter (the regularization constant for the KL divergence term) on the structure of the latent space."
      ],
      "metadata": {
        "id": "SB_pQwHPMp4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3: Using the VAE as a generator\n",
        "\n",
        "Utilize the trained VAE's generative capabilities to synthesize new, realistic handwritten digits that are not part of the original MNIST dataset.\n",
        "\n",
        "Study and discuss the impact of changing the beta parameter and the latent dimension on the quality, diversity, and realism of the generated digits.\n"
      ],
      "metadata": {
        "id": "QFy_AK64NApY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4: Using the VAE for denoising\n",
        "\n",
        "Add Gaussian noise to the input data. Investigate the effect of varying levels of noise on the performance of a VAE in denoising MNIST images. How does the VAE adapt to different noise levels, and what are the limitations?\n",
        "\n",
        "Study and discuss the impact of changing the beta parameter and the latent space dimension on the quality of the denoised reconstructions.\n"
      ],
      "metadata": {
        "id": "DswFrG7INUtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Question 5\n",
        "\n",
        "Examine the impact of different types of noise (e.g., salt-and-pepper, or speckle noise) on the VAE's denoising performance for MNIST images. How does the VAE handle various noise types, and are there specific noise types that pose more significant challenges?"
      ],
      "metadata": {
        "id": "8G35WX9cFq5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_gaussian_noise(x, stddev=0.0):\n",
        "    noise = np.random.normal(loc=0.0, scale=stddev, size=x.shape)\n",
        "    x_noisy = x + noise\n",
        "    # Clip values to keep them in [0, 1]\n",
        "    return np.clip(x_noisy, 0., 1.)\n",
        "\n",
        "def add_salt_and_pepper_noise(x, salt_prob=0.5, pepper_prob=0.1):\n",
        "    \"\"\"\n",
        "    Adds salt and pepper noise to an image.\n",
        "\n",
        "    Parameters:\n",
        "    - x: Input image array with values in [0, 1].\n",
        "    - salt_prob: Probability of adding salt (white pixels).\n",
        "    - pepper_prob: Probability of adding pepper (black pixels).\n",
        "\n",
        "    Returns:\n",
        "    - Noisy image with some pixels set to 0 (pepper) or 1 (salt).\n",
        "    \"\"\"\n",
        "    x_noisy = np.copy(x)\n",
        "    random_matrix = np.random.rand(*x.shape)\n",
        "    # Pepper noise: set pixels to 0\n",
        "    x_noisy[random_matrix < pepper_prob] = 0.0\n",
        "    # Salt noise: set pixels to 1\n",
        "    x_noisy[random_matrix > 1 - salt_prob] = 1.0\n",
        "    return x_noisy\n",
        "\n",
        "def add_speckle_noise(x, stddev=0.1):\n",
        "    \"\"\"\n",
        "    Adds speckle noise (multiplicative noise) to an image.\n",
        "\n",
        "    Parameters:\n",
        "    - x: Input image array with values in [0, 1].\n",
        "    - stddev: Standard deviation of the noise.\n",
        "\n",
        "    Returns:\n",
        "    - Noisy image computed as x + x * noise.\n",
        "    \"\"\"\n",
        "    noise = np.random.randn(*x.shape) * stddev\n",
        "    x_noisy = x + x * noise\n",
        "    return np.clip(x_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "SH6X-7Q7T4DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "Enhance the VAE architecture by replacing the dense encoder/decoder with convolutional blocks.\n",
        "\n",
        "Study and discuss the impact of this architectural change on dimensionality reduction, generation of new digits, and denoising performance."
      ],
      "metadata": {
        "id": "7yNoS6gpFqkK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}