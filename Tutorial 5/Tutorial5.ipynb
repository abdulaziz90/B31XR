{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtmEXONlGRN"
      },
      "source": [
        "\n",
        "#Graph methods for imaging, Vision and computing (B31RX) 2023\n",
        "\n",
        "##Tutorial 5: Bayesian filtering with a discrete state space\n",
        "\n",
        "In this tutorial, we will implement a Bayesian filter for online estimation of a (scalar) discrete state. We will first derive the data update step and then investigate the prediction step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "\n",
        "### Bayesian model:\n",
        "\n",
        "We consider a simple state denoted $x_t ∈ \\{0, ..., K-1\\}$, which can take $K$ values at\n",
        "each time instant. This state can vary over time with $t ∈ \\{1, ..., T\\}$\n",
        "\n",
        "\n",
        "The variations of $x$ over time is modelled by a\n",
        "homogeneous order-1 Markov chain such that the  probabilities\n",
        "\n",
        "$$f(x_{t+1} = i | x_t = j) = π_{i,j}$$\n",
        "\n",
        "are assumed to be known. Note that:\n",
        "$Σ_{i=0}^{K-1} π_{i,j} = 1$.\n",
        "\n",
        "This state is the parameter we try to estimate but it is not directly measured. Instead, we observe sequentially a set of observations $y_1, \\ldots, y_T$ distributed to binomial distributions as follows:\n",
        "\n",
        "$$\n",
        "y_t | (x_t = i) \\sim \\text{Binomial}(N, \\beta_i),\n",
        "$$\n",
        "\n",
        "where $N$ is a known integer and $\\beta_0, \\ldots, \\beta_{K-1}$ are a set of known probabilities. More precisely, if $x_t = i$, the observation $y_t$ follows a binomial distribution whose probability of success depends on the value of the state $x_t$. The probability mass function of Binomial distribution with parameters $(N, \\beta)$ is given by\n",
        "\n",
        "$$\n",
        "f(y|N, \\beta) = \\binom{N}{y} \\beta^y (1 - \\beta)^{N-y}.\n",
        "$$\n",
        "\n",
        "For simplicity, the parameter $N$ is shared across all models and does not depend on $x_t$. It should be noted that the data likelihood should be denoted by $f(y_t | (x_t = i, N, \\beta_i))$. However, since $N$ and $\\beta = \\{\\beta_0, \\ldots, \\beta_{K-1}\\}$ are assumed to be known and fixed, they are omitted to simplify the notation."
      ],
      "metadata": {
        "id": "KcXwFjOJnb0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "Assuming that $N$ and $\\beta = \\{\\beta_0, \\ldots, \\beta_{K-1}\\}$ are known and that $x_t \\in \\{0, \\ldots, K-1\\}$, derive the expression of the MLE of $x_t$ (based on $y_t$)."
      ],
      "metadata": {
        "id": "uSZmkQXNvAR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "\n",
        "Open the file $\\texttt{data_tutorial5_K=3_N=10.mat}$ and visualise the data in the variable $y$. It corresponds to $T = 1000$ observations associated with a state $x$ taking $K = 3$ values. The corresponding variables $N$ and $\\beta$ are also provided in the file. For each time instant, compute the MLE of $x_t$, and compare the estimate sequence to the ground truth state also provided in the file. What do you observe?"
      ],
      "metadata": {
        "id": "knyN4s9iwn7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "Before introducing the Bayesian filter, let's assume that a fixed prior distribution is assigned to $x_t$, i.e., we assume $f(x_t = i) = \\alpha_i$, with $\\{\\alpha_i\\}$ being known and $\\sum_{i=0}^{K-1} \\alpha_i = 1$.\n",
        "\n",
        "Derive the expression of the MAP estimator of $x_t$ (based on $y_t$ and $(\\alpha_0, \\ldots, \\alpha_{K-1})$).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LX3rjQRRxdFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "Using the prior distribution defined by $f(x_t = i) = \\alpha_i$, compute the posterior distribution of $x_t$, i.e., $f(x_t | y_t, \\alpha_0, \\ldots, \\alpha_{K-1})$."
      ],
      "metadata": {
        "id": "CdGbi2dPzIPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "Using the Bayesian filter, we will not use a fixed prior $f(x_t)$ as in Question 3 and Question 4, but the distribution $f(x_{t-1} | \\mathbf{y}_{t-1})$ where $\\mathbf{y}_{t-1} = \\{y_1, \\ldots, y_{t-1}\\}$.\n",
        "\n",
        "For simplicity, let's introduce $\\gamma_i = f(x_{t-1} = i|\\mathbf{y}_{t-1})$. This probability is obtained after the data update at iteration $(t - 1)$. By marginalising $f(x_t, x_{t-1} | \\mathbf{y}_{t-1})$, compute the adaptive prior distribution $f(x_t=i | \\mathbf{y}_{t-1})$."
      ],
      "metadata": {
        "id": "WXpx6xucz5qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "Question 6\n",
        "\n",
        "Show that the computation of the predictive distribution $f(x_t = i | \\mathbf{y}_{t-1})$ (for all $i$) can be computed using the multiplication of a $K \\times K$ matrix by a $K \\times 1$ vector.\n"
      ],
      "metadata": {
        "id": "Bu_XMy033CQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "\n",
        "Use the data in the file $\\texttt{data_tutorial5_K=3_N=10.mat}$ to implement your Bayesian filter.\n",
        "\n",
        "Initialise the prior for the initial state as follows (with strongly believe the initial state is 0 or 1):\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "f(x_1 = 0) = 0.9 \\\\\n",
        "f(x_1 = 1) = 0.1 \\\\\n",
        "f(x_1 > 1) = 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Set the transition probabilities as follows\n",
        "\n",
        "$$\n",
        "\\mathbf{P} = \\begin{bmatrix}\n",
        "0.99 & 0.005 & 0.01 \\\\\n",
        "0.01 & 0.99 & 0 \\\\\n",
        "0 & 0.005 & 0.99\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Compare the estimates obtained via Bayesian filter to those obtained via MLE."
      ],
      "metadata": {
        "id": "b46JJBDy4a04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "\n",
        "Using the same filter, estimate the state sequence in the file $\\texttt{data_tutorial5_K=3_N=5.mat}$. This data corresponds to more noisy observations obtained with $N = 5$. What do you observe?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oKVRlh--5DFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9 (Extra question)\n",
        "\n",
        "Modify your Bayesian filter assuming $K = 4$. Keep\n",
        "$$\n",
        "\\begin{cases}\n",
        "f(x_1 = 0) = 0.9 \\\\\n",
        "f(x_1 = 1) = 0.1 \\\\\n",
        "f(x_1 > 1) = 0\n",
        "\\end{cases}\n",
        "$$\n",
        "To define the initial prior distribution and use\n",
        "$$\n",
        "\\mathbf{P} = \\begin{bmatrix}\n",
        "0.99 & 0.005 & 0 & 0.05 \\\\\n",
        "0.01 & 0.99 & 0 & 0 \\\\\n",
        "0 & 0.005 & 0.99 & 0 \\\\\n",
        "0 & 0 & 0.01 & 0.95\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Using the new filter, estimate the state sequences in the files\n",
        "\n",
        "$$\\texttt{data_tutorial5_K=4_N=5.mat}$$\n",
        "\n",
        "$$\\texttt{data_tutorial5_K=4_N=10.mat}$$\n",
        "\n",
        "What do you observe?"
      ],
      "metadata": {
        "id": "40W_5h0x51LS"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}